---
title: "Getting Started"
author: "Matthew Mark Strasiotto"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Getting Started}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
#library(pipetree)
```

# Intoduction to Pipetree

The goal of pipetree is to make navigating the project structure of the 
speed-extract project as simple as possible, and to automate the most commonly
used tasks in accessing and exploring the dataset.

The most important functionalities provided are as follows:

1. Consistent access of a given dataset's root directory accross remote
   volumes, whose mount points may change ( [portrpaths::PortrPath]. )
1. Consistent Access to the filetree structure, that is used by the any 
   SPEED-EXTRACT pipeline workflow/dataset.
1. Straightforward access to the [drake::drake_cache()] for a particular 
   dataset.
   
   IE- Immediate access to the results, outputs, and targets generated by the
   data pipeline, as soon as these results are available.
1. __PLANNED__ access to structured metadata for a given dataset, so:
   1. users have useful information about the distinguishing characteristics 
      of that dataset, and 
   1. projects have useful aliases for structured and versioned logging of 
      target statistics. 
      
      Use cases for this include:
      1. Allowing versioned tracking of multiple datasets'  
         [drake::drake_cache_log], within a versioned project/repo within 
         separate subdirectories of the project that builds these targets.
      1. Allowing more in-depth data versioning, such as versioned `yaml`
         files describing high level aggregates of a given dataframe across 
         the workflow, eg
         
         ```yaml
         n_journeys: 100
         n_journeys_stemi: 5
         ```
         

# Portable Access to datasets
